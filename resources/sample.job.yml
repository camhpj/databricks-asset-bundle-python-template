resources:
  jobs:
    sample_job:
      name: sample_job
      # run_as:
      #   service_principal_name: {service_principal_name}
      # trigger:
      #   periodic:
      #     interval: 1
      #     unit: DAYS
      parameters:
        - name: catalog
          default: ${var.catalog}
        - name: schema
          default: ${var.schema}
      job_clusters:
        - job_cluster_key: sample_job_cluster
          new_cluster:
            spark_version: 17.3.x-scala2.13
            node_type_id: i3.xlarge
            num_workers: 2
            aws_attributes:
              availability: ON_DEMAND
            data_security_mode: SINGLE_USER
      tasks:
        - task_key: sample_task
          job_cluster_key: sample_job_cluster
          python_wheel_task:
            package_name: python_template
            entry_point: main
            named_parameters:
              catalog: "{{job.parameters.catalog}}"
              schema: "{{job.parameters.schema}}"
          libraries:
            - whl: dist/*.whl
      # tags are useful for cost allocation and tracking
      tags:
        job: sample_job
        bundle: ${bundle.name}
